# # -*- coding: utf-8 -*-
# """get_shop_link.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/12JI2Fz9ujD28fK8J4d2bspudmu7tYh9C
# """

# pip install requests_html

# import requests
# import urllib
# import pandas as pd
# from requests_html import HTML
# from requests_html import HTMLSession
# from app import match_product

# result = matches

# def get_source(url):
#     """Return the source code for the provided URL. 

#     Args: 
#         url (string): URL of the page to scrape.

#     Returns:
#         response (object): HTTP response object from requests_html. 
#     """

#     try:
#         session = HTMLSession()
#         response = session.get(url)
#         return response

#     except requests.exceptions.RequestException as e:
#         print(e)

# def scrape_google(queries):

#   for query in queries:
#       query = urllib.parse.quote_plus(query)
#       response = get_source("https://www.google.co.uk/search?q=" + query)

#       links = list(response.html.absolute_links)
#       google_domains = ('https://www.google.', 
#                       'https://google.', 
#                       'https://youtube.',
#                       'https://www.youtube.',
#                       'https://facebook.',
#                       'https://www.facebook.',
#                       'https://youtube.',
#                       'https://www.twitter.',
#                       'https://www.twitter.', 
#                       'https://pinterest.',
#                       'https://webcache.googleusercontent.', 
#                       'http://webcache.googleusercontent.', 
#                       'https://policies.google.',
#                       'https://support.google.',
#                       'https://maps.google.')

#       for url in links[:]:
#           if url.startswith(google_domains):
#               links.remove(url)

#       return links

# scrape_google(result)
